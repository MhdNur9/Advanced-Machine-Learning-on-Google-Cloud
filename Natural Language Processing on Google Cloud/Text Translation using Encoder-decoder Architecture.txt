Learning Objectives
In this lab, you will:

Create a tf.data.Dataset [WellSaid please say tf dot data dot dataset] for a seq2seq problem.

Train an encoder-decoder model in Keras for a translation task.

Save the encoder and the decoder as separate model.

Merge the trained encoder and decoder into a translation function.

Setup
For each lab, you get a new Google Cloud project and set of resources for a fixed time at no cost.

Sign in to Qwiklabs using an incognito window.

Note the lab's access time (for example, 1:15:00), and make sure you can finish within that time.
There is no pause feature. You can restart if needed, but you have to start at the beginning.

When ready, click Start lab.

Note your lab credentials (Username and Password). You will use them to sign in to the Google Cloud Console.

Click Open Google Console.

Click Use another account and copy/paste credentials for this lab into the prompts.
If you use other credentials, you'll receive errors or incur charges.

Accept the terms and skip the recovery resource page.

Note: Do not click End Lab unless you have finished the lab or want to restart it. This clears your work and removes the project.

Setup your environement
Enable the AI Platform Training & Prediction API
On the Navigation menu, navigate to APIs & services > Library and search for AI Platform Training & Prediction API in the search box.

Click on AI Platform Training & Prediction API, then click Enable.

Enable the Vertex AI API
In the Google Cloud Console, on the Navigation menu, click Vertex AI, and then click Enable Vertex AI API.

Create Cloud Storage Bucket
On the Navigation menu, navigate to Cloud Storage and Click on Create bucket.

Set a unique name (use your project ID because it is unique). Then, click Create.

Launch Vertex AI Notebooks
In the Google Cloud Console, on the Navigation Menu, click Vertex AI > Workbench.

On the Notebook instances page, click New Notebook > TensorFlow Enterprise > TensorFlow Enterprise 2.3 (with LTS) > Without GPUs.

In the New notebook instance dialog, confirm the name of the deep learning VM, if you donâ€™t want to region and zone leave all settings as they are and then click Create.
The new VM will take 2-3 minutes to start.

Click Open JupyterLab.
A JupyterLab window will open in a new tab.

You will see Build recommended pop up, click Build. If you see the build failed, ignore it.

Clone course repo within your Vertex AI Notebooks instance
To clone the training-data-analyst notebook in your JupyterLab instance:

In JupyterLab, to open a new terminal, click the Terminal icon.

At the command-line prompt, run the following command:

git clone https://github.com/GoogleCloudPlatform/training-data-analyst
Copied!
To confirm that you have cloned the repository, double-click on the training-data-analyst directory and ensure that you can see its contents.
The files for all the Jupyter notebook-based labs throughout this course are available in this directory.

Reusable Embeddings
Duration is 60 min

Step 1

In the notebook interface, navigate to training-data-analyst > courses > machine_learning > deepdive2 > text_classification > labs > rnn_encoder_decoder.ipynb.

Step 2

In the notebook interface, click on Edit > Clear All Outputs (click on Edit, then in the drop-down menu, select Clear All Outputs).

Carefully read through the notebook instructions and fill in lines marked with #TODO where you need to complete the code as needed

Tip: To run the current cell you can click the cell and hit shift + enter. Other cell commands are found in the notebook UI under Run.

Hints may also be provided for the tasks to guide you along. Highlight the text to read the hints (they are in white text).
If you need more help, you may take a look at the complete solution by navigating to training-data-analyst > courses > machine_learning > deepdive2 > text_classification > solutions and opening rnn_encoder_decoder.ipynb